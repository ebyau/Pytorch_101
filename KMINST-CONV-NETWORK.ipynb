{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import KMNIST\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "    def __init__(self,numChannels,classes):\n",
    "        #call the parent constructor\n",
    "        super(LeNet,self).__init__()\n",
    "        \n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels=numChannels,out_channels=20,\n",
    "                            kernel_size=(5,5))\n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        \n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        self.conv2 = Conv2d(in_channels=20,out_channels=50,\n",
    "                           kernel_size=(5,5))\n",
    "        self.relu2 = ReLU()\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=800,out_features=500)\n",
    "        self.relu3 = ReLU()\n",
    "        \n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = Linear(in_features=500,out_features=classes)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "        x = flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # pass the output to our softmax classifier to get our output\n",
    "\t\t# predictions\n",
    "        x = self.fc2(x)\n",
    "        output = self.logSoftmax(x)\n",
    "        \n",
    "        # return the output predictions\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE  = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# train and validation split\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "\n",
    "# training device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading the KMINST dataset.....\n",
      "[INFO] generating the train/validation data split....\n"
     ]
    }
   ],
   "source": [
    "# loading the KMINST dataset\n",
    "print(\"[INFO] loading the KMINST dataset.....\")\n",
    "\n",
    "trainData = KMNIST(root='data',train=True,download=True,\n",
    "                   transform=ToTensor())\n",
    "testData = KMNIST(root='data',train=False,download=True,\n",
    "                 transform=ToTensor())\n",
    "\n",
    "#calculate the train/valid split\n",
    "print(\"[INFO] generating the train/validation data split....\")\n",
    "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
    "numValSamples = int(len(trainData)* VAL_SPLIT)\n",
    "(trainData,valData) = random_split(trainData,\n",
    "        [numTrainSamples,numValSamples],\n",
    "                                   generator=torch.Generator().manual_seed(42)\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize train, validation and test data loader\n",
    "\n",
    "trainDataLoader = DataLoader(trainData,shuffle=True,\n",
    "                            batch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader(valData,batch_size=BATCH_SIZE)\n",
    "testDataLoader = DataLoader(testData,batch_size=BATCH_SIZE)\n",
    "\n",
    "#calc the steps per epoch for training and validation step\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Intializing the LeNet model.....\n",
      "[INFO] training network ....\n"
     ]
    }
   ],
   "source": [
    "#intialize the LeNet Model\n",
    "print(\"[INFO] Intializing the LeNet model.....\")\n",
    "model = LeNet(\n",
    "    numChannels=1,\n",
    "    classes=len(trainData.dataset.classes)).to(device)\n",
    "\n",
    "# initialize optimizer and loss fnx\n",
    "opt = Adam(model.parameters(),lr=INIT_LR)\n",
    "lossFn = nn.NLLLoss()\n",
    "\n",
    "# intialize history to store a dictionary to store training history\n",
    "H = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "# measure how long training will take\n",
    "print(\"[INFO] training network ....\")\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 1/10\n",
      "Train loss: 0.057091, Train accuracy: 0.9824\n",
      "Val loss: 0.085069, Val accuracy: 0.9751\n",
      "\n",
      "[INFO] total time taken to train the model: 738.18s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.97      0.89      0.93      1000\n",
      "          ki       0.96      0.93      0.95      1000\n",
      "          su       0.92      0.88      0.90      1000\n",
      "         tsu       0.96      0.93      0.94      1000\n",
      "          na       0.93      0.90      0.92      1000\n",
      "          ha       0.95      0.95      0.95      1000\n",
      "          ma       0.90      0.96      0.93      1000\n",
      "          ya       0.95      0.94      0.95      1000\n",
      "          re       0.87      0.99      0.92      1000\n",
      "          wo       0.95      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "[INFO] EPOCH: 2/10\n",
      "Train loss: 0.037549, Train accuracy: 0.9881\n",
      "Val loss: 0.085794, Val accuracy: 0.9769\n",
      "\n",
      "[INFO] total time taken to train the model: 1043.67s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.95      0.96      0.96      1000\n",
      "          ki       0.97      0.91      0.94      1000\n",
      "          su       0.87      0.89      0.88      1000\n",
      "         tsu       0.96      0.96      0.96      1000\n",
      "          na       0.94      0.94      0.94      1000\n",
      "          ha       0.97      0.90      0.93      1000\n",
      "          ma       0.90      0.97      0.94      1000\n",
      "          ya       0.94      0.98      0.96      1000\n",
      "          re       0.97      0.95      0.96      1000\n",
      "          wo       0.95      0.96      0.95      1000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "[INFO] EPOCH: 3/10\n",
      "Train loss: 0.025923, Train accuracy: 0.9917\n",
      "Val loss: 0.091718, Val accuracy: 0.9752\n",
      "\n",
      "[INFO] total time taken to train the model: 1288.19s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.93      0.98      0.95      1000\n",
      "          ki       0.98      0.90      0.94      1000\n",
      "          su       0.83      0.90      0.86      1000\n",
      "         tsu       0.92      0.97      0.95      1000\n",
      "          na       0.97      0.92      0.94      1000\n",
      "          ha       0.96      0.93      0.95      1000\n",
      "          ma       0.90      0.92      0.91      1000\n",
      "          ya       0.95      0.98      0.96      1000\n",
      "          re       0.95      0.97      0.96      1000\n",
      "          wo       0.99      0.90      0.95      1000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "[INFO] EPOCH: 4/10\n",
      "Train loss: 0.018787, Train accuracy: 0.9940\n",
      "Val loss: 0.090951, Val accuracy: 0.9793\n",
      "\n",
      "[INFO] total time taken to train the model: 1364.56s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.94      0.97      0.95      1000\n",
      "          ki       0.93      0.94      0.94      1000\n",
      "          su       0.94      0.86      0.90      1000\n",
      "         tsu       0.95      0.97      0.96      1000\n",
      "          na       0.97      0.91      0.94      1000\n",
      "          ha       0.97      0.94      0.96      1000\n",
      "          ma       0.87      0.98      0.92      1000\n",
      "          ya       0.95      0.97      0.96      1000\n",
      "          re       0.97      0.95      0.96      1000\n",
      "          wo       0.98      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[INFO] EPOCH: 5/10\n",
      "Train loss: 0.016620, Train accuracy: 0.9948\n",
      "Val loss: 0.078089, Val accuracy: 0.9811\n",
      "\n",
      "[INFO] total time taken to train the model: 1629.53s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.95      0.96      0.95      1000\n",
      "          ki       0.97      0.94      0.95      1000\n",
      "          su       0.89      0.90      0.90      1000\n",
      "         tsu       0.92      0.98      0.95      1000\n",
      "          na       0.97      0.91      0.94      1000\n",
      "          ha       0.97      0.93      0.95      1000\n",
      "          ma       0.91      0.96      0.94      1000\n",
      "          ya       0.96      0.94      0.95      1000\n",
      "          re       0.94      0.97      0.96      1000\n",
      "          wo       0.96      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[INFO] EPOCH: 6/10\n",
      "Train loss: 0.014943, Train accuracy: 0.9950\n",
      "Val loss: 0.081835, Val accuracy: 0.9801\n",
      "\n",
      "[INFO] total time taken to train the model: 1671.89s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.94      0.95      0.95      1000\n",
      "          ki       0.93      0.94      0.94      1000\n",
      "          su       0.90      0.92      0.91      1000\n",
      "         tsu       0.96      0.97      0.96      1000\n",
      "          na       0.94      0.93      0.94      1000\n",
      "          ha       0.98      0.93      0.95      1000\n",
      "          ma       0.96      0.93      0.94      1000\n",
      "          ya       0.95      0.95      0.95      1000\n",
      "          re       0.93      0.97      0.95      1000\n",
      "          wo       0.94      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "[INFO] EPOCH: 7/10\n",
      "Train loss: 0.010604, Train accuracy: 0.9966\n",
      "Val loss: 0.079217, Val accuracy: 0.9829\n",
      "\n",
      "[INFO] total time taken to train the model: 1736.81s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.94      0.96      0.95      1000\n",
      "          ki       0.92      0.94      0.93      1000\n",
      "          su       0.94      0.90      0.92      1000\n",
      "         tsu       0.96      0.97      0.96      1000\n",
      "          na       0.95      0.94      0.94      1000\n",
      "          ha       0.97      0.94      0.96      1000\n",
      "          ma       0.91      0.97      0.94      1000\n",
      "          ya       0.97      0.94      0.95      1000\n",
      "          re       0.96      0.96      0.96      1000\n",
      "          wo       0.96      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[INFO] EPOCH: 8/10\n",
      "Train loss: 0.009259, Train accuracy: 0.9970\n",
      "Val loss: 0.082399, Val accuracy: 0.9812\n",
      "\n",
      "[INFO] total time taken to train the model: 1778.47s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.95      0.97      0.96      1000\n",
      "          ki       0.98      0.91      0.94      1000\n",
      "          su       0.93      0.90      0.91      1000\n",
      "         tsu       0.93      0.98      0.96      1000\n",
      "          na       0.94      0.95      0.95      1000\n",
      "          ha       0.97      0.94      0.95      1000\n",
      "          ma       0.91      0.97      0.94      1000\n",
      "          ya       0.98      0.94      0.96      1000\n",
      "          re       0.93      0.98      0.95      1000\n",
      "          wo       0.98      0.94      0.96      1000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "[INFO] EPOCH: 9/10\n",
      "Train loss: 0.006000, Train accuracy: 0.9983\n",
      "Val loss: 0.085248, Val accuracy: 0.9834\n",
      "\n",
      "[INFO] total time taken to train the model: 1824.56s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.97      0.95      0.96      1000\n",
      "          ki       0.96      0.94      0.95      1000\n",
      "          su       0.92      0.92      0.92      1000\n",
      "         tsu       0.96      0.97      0.96      1000\n",
      "          na       0.96      0.92      0.94      1000\n",
      "          ha       0.96      0.95      0.95      1000\n",
      "          ma       0.94      0.96      0.95      1000\n",
      "          ya       0.97      0.96      0.96      1000\n",
      "          re       0.94      0.99      0.96      1000\n",
      "          wo       0.95      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 10/10\n",
      "Train loss: 0.009393, Train accuracy: 0.9970\n",
      "Val loss: 0.096164, Val accuracy: 0.9797\n",
      "\n",
      "[INFO] total time taken to train the model: 1867.96s\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           o       0.95      0.96      0.96      1000\n",
      "          ki       0.98      0.92      0.95      1000\n",
      "          su       0.87      0.92      0.90      1000\n",
      "         tsu       0.95      0.97      0.96      1000\n",
      "          na       0.93      0.94      0.93      1000\n",
      "          ha       0.96      0.92      0.94      1000\n",
      "          ma       0.93      0.96      0.94      1000\n",
      "          ya       0.98      0.95      0.96      1000\n",
      "          re       0.92      0.99      0.95      1000\n",
      "          wo       0.98      0.93      0.96      1000\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.94      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,EPOCHS):\n",
    "    # intialize model training,train loss and validation loss\n",
    "    model.train()\n",
    "    \n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "    \n",
    "    # intialize n0. of correct predictions in train and val step\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "    \n",
    "    # loop over training set\n",
    "    for (x,y) in trainDataLoader:\n",
    "        \n",
    "        #send input data to device\n",
    "        (x,y) = (x.to(device),y.to(device))\n",
    "        \n",
    "        # forward pass and calc train loss\n",
    "        pred = model(x)\n",
    "        loss = lossFn(pred,y)\n",
    "        \n",
    "        # zero the gradients, perform backpropagation and update weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        #compute total loss and calc num of correct predictions\n",
    "        totalTrainLoss += loss\n",
    "        trainCorrect += (pred.argmax(1)==y).type(\n",
    "        torch.float).sum().item()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # turn off autograd for evaluation\n",
    "    with torch.no_grad():\n",
    "        # intialize model evaluation\n",
    "        model.eval()\n",
    "        \n",
    "        # loop over validation set\n",
    "        for (x,y) in valDataLoader:\n",
    "            #transfer data to device\n",
    "            (x,y) = (x.to(device),y.to(device))\n",
    "            \n",
    "            # make predictions and compute loss\n",
    "            pred = model(x)\n",
    "            totalValLoss += lossFn(pred,y)\n",
    "            \n",
    "            # calc the num of correct predictions\n",
    "            valCorrect += (pred.argmax(1)==y).type(\n",
    "            torch.float).sum().item()\n",
    "            \n",
    "    # average train and validation loss        \n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "    \n",
    "    # calc training and validation accuracy\n",
    "    trainCorrect = trainCorrect / len(trainDataLoader.dataset)\n",
    "    valCorrect = valCorrect / len(valDataLoader.dataset)\n",
    "    \n",
    "    # update trianing history\n",
    "    H['train_loss'].append(avgTrainLoss.cpu().detach().numpy)\n",
    "    H['train_acc'].append(trainCorrect)\n",
    "    H['val_loss'].append(avgValLoss.cpu().detach().numpy())\n",
    "    H['val_acc'].append(valCorrect)\n",
    "    \n",
    "    # print the model trianing and validation information\n",
    "    \n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(epoch+1,EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "    avgTrainLoss,trainCorrect))\n",
    "    print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
    "    avgValLoss,valCorrect))\n",
    "    \n",
    "    # finish measuring how long training took\n",
    "    endTime = time.time()\n",
    "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "        endTime - startTime))\n",
    "    # we can now evaluate the network on the test set\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    # turn off autograd for testing evaluation\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # initialize a list to store our predictions\n",
    "        preds = []\n",
    "        # loop over the test set\n",
    "        for (x, y) in testDataLoader:\n",
    "            # send the input to the device\n",
    "            x = x.to(device)\n",
    "            # make the predictions and add them to the list\n",
    "            pred = model(x)\n",
    "            preds.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "    # generate a classification report\n",
    "    print(classification_report(testData.targets.cpu().numpy(),\n",
    "        np.array(preds), target_names=testData.classes))\n",
    "            \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
